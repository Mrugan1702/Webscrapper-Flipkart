import bs4
from bs4 import BeautifulSoup
import requests
import pandas as pd
import csv  # Add this import statement

link = input('Paste the link of the second page of Reviews page here:\n')
page = link[-1:]
page = int(page)

try:
    # Open the CSV file for writing, and add column header if it doesn't exist
    with open('Finalreviews.csv', mode='a', newline='', encoding='utf-8') as file:
        header = ['reviews']
        writer = csv.writer(file)
        
        # Check if the file is empty (no header yet), add the header if needed
        if file.tell() == 0:
            writer.writerow(header)

        for i in range(page - 1, 125):
            new_link = link.rstrip('2')
            i = str(i)
            output_link = new_link + i
            print(output_link)
            page = requests.get(output_link)
            page.raise_for_status()  # Check for HTTP errors
            page_content = page.content  # Save the page content

            soup = BeautifulSoup(page_content, 'html.parser')
            new_rev = []

            # Find all review divs and extract their text
            for j in soup.find_all('div', class_="_6t1WkM _3HqJxg"):
                new_rev.append(j.text.strip())

            if new_rev:
                # Open the CSV file again and append the new reviews
                with open('Finalreviews.csv', mode='a', newline='', encoding='utf-8') as file:
                    writer = csv.writer(file)
                    for review in new_rev:
                        writer.writerow([review])

            print("Reviews added to CSV:", len(new_rev))

except requests.exceptions.RequestException as e:
    print(f"Error: {e}")
except Exception as ex:
    print(f"An error occurred: {ex}")
